{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Updated_R7_ExternalLab_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WH1Pr4KQlCh",
        "colab_type": "text"
      },
      "source": [
        "### Build a DNN using Keras with `RELU` and `ADAM`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbvI8LqlQlCl",
        "colab_type": "text"
      },
      "source": [
        "#### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPW-a-qYQlCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cQBsi5QlCw",
        "colab_type": "text"
      },
      "source": [
        "#### Collect Fashion mnist data from tf.keras.datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVWy0oDTr2Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainX, trainY),(testX, testY) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no7aWYZyQlC1",
        "colab_type": "text"
      },
      "source": [
        "#### Change train and test labels into one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX6otc4wQlC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjNrRTdoQlC5",
        "colab_type": "text"
      },
      "source": [
        "#### Build the Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDJ9DHVNQlC7",
        "colab_type": "text"
      },
      "source": [
        "#### Initialize model, reshape & normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCDQs_g1QlC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBGwTTilQlDD",
        "colab_type": "text"
      },
      "source": [
        "#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXbfpfOzQlDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I8f5otcQlDJ",
        "colab_type": "text"
      },
      "source": [
        "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZkvKymSd0Sr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "fb14767d-9d7b-4e54-a5b1-57ccf282eee4"
      },
      "source": [
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 181,246\n",
            "Trainable params: 179,678\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q4QEQxgMggl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a38fd2ae-5cdd-4cf3-abdb-72b8a2140c2a"
      },
      "source": [
        "model.fit(trainX,trainY,          \n",
        "          validation_data=(testX,testY),\n",
        "          epochs=30,\n",
        "          batch_size=30)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 11s 178us/sample - loss: 0.2633 - acc: 0.9206 - val_loss: 0.3040 - val_acc: 0.9611\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.1323 - acc: 0.9603 - val_loss: 0.3419 - val_acc: 0.9657\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 10s 169us/sample - loss: 0.1029 - acc: 0.9683 - val_loss: 0.3560 - val_acc: 0.9674\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 10s 173us/sample - loss: 0.0847 - acc: 0.9733 - val_loss: 0.2696 - val_acc: 0.9704\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 10s 169us/sample - loss: 0.0744 - acc: 0.9764 - val_loss: 0.3075 - val_acc: 0.9712\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0621 - acc: 0.9804 - val_loss: 0.2546 - val_acc: 0.9706\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0542 - acc: 0.9828 - val_loss: 0.3065 - val_acc: 0.9696\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0528 - acc: 0.9831 - val_loss: 0.2750 - val_acc: 0.9672\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 10s 174us/sample - loss: 0.0476 - acc: 0.9853 - val_loss: 0.5492 - val_acc: 0.9703\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0443 - acc: 0.9863 - val_loss: 0.2634 - val_acc: 0.9748\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0420 - acc: 0.9871 - val_loss: 0.5318 - val_acc: 0.9715\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0428 - acc: 0.9869 - val_loss: 0.5166 - val_acc: 0.9715\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0372 - acc: 0.9886 - val_loss: 0.2676 - val_acc: 0.9727\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0360 - acc: 0.9890 - val_loss: 0.3217 - val_acc: 0.9728\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0353 - acc: 0.9889 - val_loss: 0.4084 - val_acc: 0.9708\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0337 - acc: 0.9895 - val_loss: 0.3578 - val_acc: 0.9727\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0336 - acc: 0.9896 - val_loss: 0.4446 - val_acc: 0.9701\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 11s 177us/sample - loss: 0.0303 - acc: 0.9908 - val_loss: 0.3513 - val_acc: 0.9721\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 10s 175us/sample - loss: 0.0313 - acc: 0.9905 - val_loss: 0.4877 - val_acc: 0.9744\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0300 - acc: 0.9911 - val_loss: 0.3833 - val_acc: 0.9745\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 10s 174us/sample - loss: 0.0285 - acc: 0.9914 - val_loss: 0.2943 - val_acc: 0.9733\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0286 - acc: 0.9918 - val_loss: 0.3973 - val_acc: 0.9726\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 11s 176us/sample - loss: 0.0282 - acc: 0.9918 - val_loss: 0.4098 - val_acc: 0.9717\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 11s 177us/sample - loss: 0.0233 - acc: 0.9925 - val_loss: 0.3901 - val_acc: 0.9716\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 10s 174us/sample - loss: 0.0288 - acc: 0.9913 - val_loss: 0.4216 - val_acc: 0.9719\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0274 - acc: 0.9921 - val_loss: 0.4089 - val_acc: 0.9712\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 10s 175us/sample - loss: 0.0265 - acc: 0.9922 - val_loss: 0.3376 - val_acc: 0.9750\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0264 - acc: 0.9923 - val_loss: 0.5439 - val_acc: 0.9723\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 11s 182us/sample - loss: 0.0257 - acc: 0.9927 - val_loss: 0.4602 - val_acc: 0.9710\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 11s 180us/sample - loss: 0.0233 - acc: 0.9931 - val_loss: 0.4593 - val_acc: 0.9727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6b93b07978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}